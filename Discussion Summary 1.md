## Discussion Topic: Codes of Ethics and Professional Conduct ##


## Initial Post: UX Dark Patterns ##

Dark UX patterns that mislead or manipulate users with unintended or undesirable consequences are unethical and can harm users (Brignull, 2013). In one case where a customer was using dark patterns to generate revenue, a computer expert raised concerns with a manager, only to be informed that these changes were requested by the customer (‘Case: Dark UX Patterns - ACM Ethics’, 2018). These patterns may violate several principles of the BCS Code of Conduct, consumer protection and accessibility laws, and may undermine trust between users and businesses.

A computer scientist has a moral obligation to use his skills for the benefit of society and to avoid deception and discrimination. The BCS Code of Conduct provides guidance for computer professionals to ensure their work is ethical. The failure of computer professionals and their managers to take a proactive stance in identifying and addressing ethical issues is consistent with their policy to ensure that client designs do not deceive or harm users. It suggests the need for a process.

The use of dark patterns raises ethical, legal, social and professional issues. Computer professionals must ensure that their work meets the highest ethical standards and take proactive steps to identify and mitigate potential ethical issues. Sources such as the BCS Code of Conduct and consumer protection and accessibility laws provide useful frameworks for ethical behavior among computing professionals.

 

Brignull, H. (2011) Dark Patterns: Deception vs. Honesty in UI Design, A List Apart. Available at: https://alistapart.com/article/dark-patterns-deception-vs-honesty-in-ui-design/ (Accessed: 7 May 2023).

British Computer Society Code of Conduct (2022) Available from: https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf (Accessed 7 May 2023)

‘Case: Dark UX Patterns - ACM Ethics’ (2018), 10 July. Available at: https://ethics.acm.org/code-of-ethics/using-the-code/case-dark-ux-patterns/ (Accessed: 7 May 2023).

## Respondse by Vasilisa Lukashevich ##

Thank you for the post – the Dark UI/UX Patterns topic seems very relevant, since each digital consumer has faced this problem at least once in their life. For example, some “leaveshaming” banners on the app/website like “Leaving so soon, _username_?” or hidden costs. There are a lot of examples on Twitter tagged as @darkpatterns to research. In fact sometimes user manipulations go so subtle that they cannot explain with one screenshot what is wrong.

Moreover, like Waldman (2020) noticed, “users routinely trade privacy for convenience”. Many consumers feel free with sharing their geolocation, plus the overall trend toward personalization, and that opens the way to weaponize dark patterns against users easily. Sell companies use AI methods to find users' weak spots, determining which interface, text, juxtapositions, and color maximize revenues (Luguri & Strahilevitz, 2021).

From this point of view, we might try to use AI to defend the users as well. According to the quick research, there is some work in progress. For instance, a group of scholars tried automated detection of five dark patterns (Nagging, Obstruction, Sneaking, Interface Interference, Forced action) by Machine Learning methods. (Soe et al., 2022). The best accuracy demonstrated by Nagging detection – 72%, the rest allowed a lot of room for improvement.

References:

Luguri, J. & Strahilevitz, L.J. (2021) Shining a light on dark patterns. Journal of Legal Analysis, 13(1), pp.43-109.

Waldman, A.E. (2020) Cognitive biases, dark patterns, and the ‘privacy paradox’. Current opinion in psychology, 31, pp.105-109.

Soe, T.H., Santos, C.T. & Slavkovik, M. (2022) Automated detection of dark patterns in cookie banners: how to do it poorly and why it is hard to do it any other way. arXiv preprint arXiv:2204.11836. 


## Summary Post ##

Dark UX patterns that manipulate and harm users are unethical and can violate the BCS Code of Conduct, consumer protection, and accessibility laws. These patterns undermine trust between users and businesses, and a proactive approach is needed to identify and address ethical issues. While some organizations prioritize revenue generation over user well-being, computer professionals have a moral obligation to use their skills for the benefit of society and avoid deception and discrimination.

The growing trend of trading privacy for convenience enables dark patterns to exploit users' vulnerabilities. Companies leverage AI methods to identify and maximize revenue from users.
To combat these issues, efforts are underway to detect and mitigate dark patterns using machine learning. Researchers have focused on automated detection of patterns like nagging, obstruction, sneaking, interface interference, and forced action. While accuracy rates vary, particularly with nagging detection reaching 72%, further improvements are possible.
